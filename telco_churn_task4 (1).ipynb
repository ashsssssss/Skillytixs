{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ca6364",
   "metadata": {},
   "source": [
    "\n",
    "# Task 4 — Telco Customer Churn: ML Pipeline (Notebook)\n",
    "**Objective:** Predict customer churn using the provided Telco customer churn dataset.\n",
    "\n",
    "**This notebook will:**  \n",
    "- Load the CSV from the path you gave.  \n",
    "- Perform EDA (missing values, target balance, basic visuals).  \n",
    "- Clean and preprocess (types, `TotalCharges` conversion, missing handling).  \n",
    "- Encode categorical features (LabelEncoder for binary, one-hot for multi-class).  \n",
    "- Scale numeric features where appropriate.  \n",
    "- Train baseline models (Logistic Regression, RandomForest).  \n",
    "- Evaluate using accuracy, ROC-AUC, confusion matrix, classification report.  \n",
    "- Show feature importances and save a best model with `joblib`.  \n",
    "- Save predictions (CSV) ready for inspection.\n",
    "\n",
    "> **File path used to load data:**  \n",
    "`C:\\Users\\admin\\OneDrive\\Desktop\\skillyt\\telco\\WA_Fn-UseC_-Telco-Customer-Churn.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3dcaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 0 — Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, confusion_matrix, \n",
    "                             classification_report, roc_curve, auc)\n",
    "import joblib\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "sns.set_style('whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7889691",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1 — Load data\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\admin\\\\OneDrive\\\\Desktop\\\\skillyt\\\\telco\\\\WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6231cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2 — Quick EDA\n",
    "print('Columns:', df.columns.tolist())\n",
    "print('\\nTarget distribution (Churn):')\n",
    "print(df['Churn'].value_counts())\n",
    "sns.countplot(x='Churn', data=df)\n",
    "plt.title('Churn distribution')\n",
    "plt.show()\n",
    "\n",
    "print('\\nMissing values:')\n",
    "display(df.isnull().sum()[df.isnull().sum()>0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143f9ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Observations: TotalCharges is sometimes blank/space; convert to numeric\n",
    "print('TotalCharges sample values that are non-numeric:')\n",
    "mask = df['TotalCharges'].apply(lambda x: isinstance(x, str) and x.strip()=='')\n",
    "display(df[mask].head())\n",
    "\n",
    "# Convert TotalCharges to numeric, coerce errors (will produce NaN for blanks)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "print('Number of NaNs in TotalCharges:', df['TotalCharges'].isna().sum())\n",
    "\n",
    "# For rows with missing TotalCharges, we can fill with MonthlyCharges * tenure (approx)\n",
    "df.loc[df['TotalCharges'].isna(), 'TotalCharges'] = df.loc[df['TotalCharges'].isna(), 'MonthlyCharges'] * df.loc[df['TotalCharges'].isna(), 'tenure']\n",
    "print('After imputation, NaNs in TotalCharges:', df['TotalCharges'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a49b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3 — Feature types and simple feature creation\n",
    "# Convert 'SeniorCitizen' to categorical (it is 0/1 integer)\n",
    "df['SeniorCitizen'] = df['SeniorCitizen'].astype('int')\n",
    "\n",
    "# Create a few useful features\n",
    "df['AvgMonthlyCharge'] = df['TotalCharges'] / (df['tenure'].replace(0,1))  # avoid divide by zero\n",
    "df['HasPhoneService'] = (df['PhoneService'] == 'Yes').astype(int)\n",
    "df['MultipleLines_flag'] = df['MultipleLines'].replace({'No phone service':'No', 'No':'No', 'Yes':'Yes'})\n",
    "df['MultipleLines_flag'] = (df['MultipleLines_flag'] == 'Yes').astype(int)\n",
    "\n",
    "df[['tenure','MonthlyCharges','TotalCharges','AvgMonthlyCharge']].describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82077110",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4 — Encoding\n",
    "# Target encode\n",
    "le_target = LabelEncoder()\n",
    "df['Churn_flag'] = le_target.fit_transform(df['Churn'])  # No=0, Yes=1\n",
    "\n",
    "# Identify categorical features\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "# Remove target and customerID-like fields from cat_cols\n",
    "cat_cols = [c for c in cat_cols if c not in ['customerID','Churn']]\n",
    "print('Categorical columns:', cat_cols)\n",
    "\n",
    "# For binary object columns like 'Yes'/'No' we can use LabelEncoder; for multi-class use get_dummies\n",
    "bin_cols = [c for c in cat_cols if df[c].nunique() == 2]\n",
    "multi_cols = [c for c in cat_cols if df[c].nunique() > 2]\n",
    "print('Binary categorical cols:', bin_cols)\n",
    "print('Multi-class categorical cols:', multi_cols)\n",
    "\n",
    "# Label encode binary columns\n",
    "le = LabelEncoder()\n",
    "for c in bin_cols:\n",
    "    df[c] = le.fit_transform(df[c])\n",
    "\n",
    "# One-hot encode multi-class (drop first to avoid multicollinearity)\n",
    "df = pd.get_dummies(df, columns=multi_cols, drop_first=True)\n",
    "print('Shape after encoding:', df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5 — Prepare X, y and train-test split\n",
    "drop_cols = ['customerID','Churn','Churn_flag']  # keep churn_flag separately\n",
    "X = df.drop(columns=drop_cols, errors='ignore')\n",
    "y = df['Churn_flag']\n",
    "\n",
    "# Train-test split (stratify because classes may be imbalanced)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b26e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 6 — Feature scaling for models that need it (Logistic Regression)\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# We'll scale only a subset (numeric continuous columns)\n",
    "cont_cols = ['tenure','MonthlyCharges','TotalCharges','AvgMonthlyCharge']\n",
    "cont_cols = [c for c in cont_cols if c in X.columns]\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[cont_cols] = scaler.fit_transform(X_train[cont_cols])\n",
    "X_test_scaled[cont_cols]  = scaler.transform(X_test[cont_cols])\n",
    "\n",
    "print('Scaled continuous columns:', cont_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567aa9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7 — Baseline model: Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "y_proba = logreg.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, y_proba))\n",
    "print('\\nClassification report:\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Logistic Regression Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0b6242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 8 — Random Forest (no need to scale)\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_proba_rf = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('RF Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
    "print('RF ROC-AUC:', roc_auc_score(y_test, y_proba_rf))\n",
    "print('\\nRF Classification report:\\n', classification_report(y_test, y_pred_rf))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')\n",
    "plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Random Forest Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee3a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 9 — Feature importance (from Random Forest)\n",
    "importances = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "display(importances.head(30))\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "importances.head(20).plot(kind='barh')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Top 20 Feature Importances (RF)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 10 — ROC curve comparison\n",
    "fpr1, tpr1, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc1 = auc(fpr1, tpr1)\n",
    "\n",
    "fpr2, tpr2, _ = roc_curve(y_test, y_proba_rf)\n",
    "roc_auc2 = auc(fpr2, tpr2)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr1, tpr1, label=f'LogReg (AUC = {roc_auc1:.3f})')\n",
    "plt.plot(fpr2, tpr2, label=f'RandomForest (AUC = {roc_auc2:.3f})')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688cb1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 11 — Save best model (choose RF here) and create predictions file\n",
    "joblib.dump(rf, 'telco_rf_model.joblib')\n",
    "print('Saved Random Forest model to telco_rf_model.joblib')\n",
    "\n",
    "# Predictions CSV with probabilities for inspection\n",
    "preds_df = X_test.copy()\n",
    "preds_df['actual_churn'] = y_test.values\n",
    "preds_df['pred_churn'] = y_pred_rf\n",
    "preds_df['pred_proba'] = y_proba_rf\n",
    "preds_df.to_csv('telco_churn_test_predictions.csv', index=False)\n",
    "print('Saved telco_churn_test_predictions.csv (rows: {})'.format(preds_df.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05864f3",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Next steps & interview prep\n",
    "- Try hyperparameter tuning (GridSearchCV) for the Random Forest and Logistic Regression.  \n",
    "- Handle class imbalance (if present) with class weights, resampling (SMOTE), or threshold tuning.  \n",
    "- Explain why we scaled some features and not others.  \n",
    "- Be ready to talk about feature engineering choices (e.g., TotalCharges imputation, AvgMonthlyCharge).\n",
    "\n",
    "**If you'd like**, I can also:\n",
    "- Add GridSearchCV for RF, or\n",
    "- Create a simpler export with selected features for model deployment.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
